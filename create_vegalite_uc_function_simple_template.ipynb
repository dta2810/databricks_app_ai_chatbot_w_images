{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df4a05d-9408-4485-bab2-3c5a2aa340c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create and Test Vega-Lite UC Function (Simple Version)\n",
    "\n",
    "This is a simplified version that returns hardcoded Vega-Lite specs.\n",
    "Use this to test the UC Function creation process without needing Foundation Model access.\n",
    "\n",
    "## Prerequisites\n",
    "- USAGE + CREATE permissions on your catalog.schema\n",
    "- That's it! No LLM access needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b199949c-1e58-4b0c-9a57-d238ad33516a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-sdk in /databricks/python3/lib/python3.10/site-packages (0.20.0)\nCollecting databricks-sdk\n  Downloading databricks_sdk-0.88.0-py3-none-any.whl (798 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.3/798.3 kB 9.3 MB/s eta 0:00:00\nCollecting unitycatalog-ai\n  Downloading unitycatalog_ai-0.3.2-py3-none-any.whl (66 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 11.0 MB/s eta 0:00:00\nCollecting typing_extensions>=4.7.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 21.0 MB/s eta 0:00:00\nCollecting databricks-connect>=15.1.0\n  Downloading databricks_connect-16.1.7-py2.py3-none-any.whl (2.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 21.9 MB/s eta 0:00:00\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk) (2.28.1)\nCollecting protobuf!=5.26.*,!=5.27.*,!=5.28.*,!=5.29.0,!=5.29.1,!=5.29.2,!=5.29.3,!=5.29.4,!=6.30.0,!=6.30.1,!=6.31.0,<7.0,>=4.25.8\n  Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 323.5/323.5 kB 32.5 MB/s eta 0:00:00\nRequirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk) (2.28.1)\nCollecting unitycatalog-client\n  Downloading unitycatalog_client-0.4.0-py3-none-any.whl (180 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 180.3/180.3 kB 42.9 MB/s eta 0:00:00\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.10/site-packages (from unitycatalog-ai) (1.10.6)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.10/site-packages (from unitycatalog-ai) (1.5.6)\nCollecting cloudpickle\n  Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (0.10.9.7)\nRequirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (1.62.0)\nRequirement already satisfied: grpcio>=1.59.3 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (1.62.0)\nRequirement already satisfied: numpy<2,>=1.15 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (1.23.5)\nRequirement already satisfied: pyarrow>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (8.0.0)\nRequirement already satisfied: pandas>=1.0.5 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (1.5.3)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect>=15.1.0) (1.16.0)\nRequirement already satisfied: grpcio-status>=1.59.3 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (1.62.0)\nRequirement already satisfied: packaging>=23.2 in /databricks/python3/lib/python3.10/site-packages (from databricks-connect>=15.1.0) (23.2)\nCollecting setuptools>=68.0.0\n  Downloading setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 33.8 MB/s eta 0:00:00\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (0.3.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (5.3.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (4.9)\nCollecting protobuf!=5.26.*,!=5.27.*,!=5.28.*,!=5.29.0,!=5.29.1,!=5.29.2,!=5.29.3,!=5.29.4,!=6.30.0,!=6.30.1,!=6.31.0,<7.0,>=4.25.8\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.9/294.9 kB 36.3 MB/s eta 0:00:00\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.0.5->databricks-connect>=15.1.0) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas>=1.0.5->databricks-connect>=15.1.0) (2.8.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (1.26.14)\nCollecting aiohttp>=3.8.4\n  Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 44.4 MB/s eta 0:00:00\nCollecting aiohttp-retry>=2.8.3\n  Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\nCollecting pydantic\n  Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 463.6/463.6 kB 48.7 MB/s eta 0:00:00\nCollecting pydantic-core==2.41.5\n  Downloading pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 64.8 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting typing-inspection>=0.4.2\n  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai) (22.1.0)\nCollecting frozenlist>=1.1.1\n  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 219.5/219.5 kB 70.2 MB/s eta 0:00:00\nCollecting async-timeout<6.0,>=4.0\n  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\nCollecting yarl<2.0,>=1.17.0\n  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 347.0/347.0 kB 80.8 MB/s eta 0:00:00\nCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.7.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (243 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 243.3/243.3 kB 35.8 MB/s eta 0:00:00\nCollecting propcache>=0.2.0\n  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.9/196.9 kB 52.2 MB/s eta 0:00:00\nCollecting aiohappyeyeballs>=2.5.0\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nCollecting aiosignal>=1.4.0\n  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk) (0.5.1)\nInstalling collected packages: typing_extensions, setuptools, protobuf, propcache, frozenlist, cloudpickle, async-timeout, annotated-types, aiohappyeyeballs, typing-inspection, pydantic-core, multidict, aiosignal, yarl, pydantic, databricks-sdk, databricks-connect, aiohttp, aiohttp-retry, unitycatalog-client, unitycatalog-ai\n  Attempting uninstall: typing_extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 65.5.1\n    Not uninstalling setuptools at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'setuptools'. No files were found to uninstall.\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.25.5\n    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.20.0\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n  Attempting uninstall: databricks-connect\n    Found existing installation: databricks-connect 14.3.14\n    Not uninstalling databricks-connect at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461\n    Can't uninstall 'databricks-connect'. No files were found to uninstall.\nSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiohttp-retry-2.9.1 aiosignal-1.4.0 annotated-types-0.7.0 async-timeout-5.0.1 cloudpickle-3.1.2 databricks-connect-16.1.7 databricks-sdk-0.88.0 frozenlist-1.8.0 multidict-6.7.1 propcache-0.4.1 protobuf-4.25.8 pydantic-2.12.5 pydantic-core-2.41.5 setuptools-82.0.0 typing-inspection-0.4.2 typing_extensions-4.15.0 unitycatalog-ai-0.3.2 unitycatalog-client-0.4.0 yarl-1.22.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install databricks-sdk unitycatalog-ai typing_extensions>=4.7.0 databricks-connect>=15.1.0 --upgrade\n",
    "dbutils.library.restartPython()  # Comment out for local execution via dbconnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "511fb65b-81ab-4bc0-ae87-0ea835ce1200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Configure Your Catalog and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "536a8417-8cf3-4dc7-a943-1ffe6792bb9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using main_david_thomas.default\n"
     ]
    }
   ],
   "source": [
    "# TODO: EDIT THESE VALUES\n",
    "CATALOG = \"your_catalog\"  # Change to your catalog name\n",
    "SCHEMA = \"your_schema\"  # Change to your schema name\n",
    "\n",
    "# Verify you have permissions\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "print(f\"✅ Using {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "760d9844-1c04-4214-8759-41b85fac251d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Define a Simple Vega-Lite Generator\n",
    "\n",
    "This version returns template specs based on keywords (no LLM needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "552f86f7-ff75-493b-a8d3-a795e8fc9e77",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 6"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Vega-Lite Specification Generator for Databricks Unity Catalog\n",
    "\n",
    "This function generates Vega-Lite v5 specifications with intelligent multi-scale support.\n",
    "It automatically detects when metrics have vastly different scales (e.g., USD millions vs Volume thousands)\n",
    "and uses dual-axis charts or separate subplots for clarity.\n",
    "\n",
    "Key Features:\n",
    "- Smart field type detection (time, category, value fields)\n",
    "- Year-over-year comparison support\n",
    "- Multi-scale metric visualization (dual-axis, subplots)\n",
    "- Grouped bar charts for multi-metric analysis\n",
    "- Line charts with multi-series support\n",
    "- Scatter plots, pie charts, and more\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_vega_lite_spec(\n",
    "    chart_description: str,\n",
    "    data_sample: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a Vega-Lite visualization specification from a description.\n",
    "    \n",
    "    Enhanced version with multi-scale support for comparing metrics with different scales.\n",
    "    \n",
    "    Args:\n",
    "        chart_description (str): Natural language description of the chart.\n",
    "        data_sample (str): JSON string array of objects.\n",
    "    \n",
    "    Returns:\n",
    "        str: JSON string containing a valid Vega-Lite v5 specification\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    \n",
    "    # Validation\n",
    "    if not chart_description or not chart_description.strip():\n",
    "        return json.dumps({\n",
    "            \"error\": \"chart_description cannot be empty\",\n",
    "            \"status\": \"failed\"\n",
    "        })\n",
    "    \n",
    "    # Parse data with fallback\n",
    "    data_values = []\n",
    "    try:\n",
    "        if data_sample and data_sample.strip():\n",
    "            parsed = json.loads(data_sample)\n",
    "            if isinstance(parsed, list) and len(parsed) > 0:\n",
    "                data_values = parsed\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    # Default sample data if none provided\n",
    "    if not data_values:\n",
    "        data_values = [\n",
    "            {\"category\": \"A\", \"value\": 28},\n",
    "            {\"category\": \"B\", \"value\": 55},\n",
    "            {\"category\": \"C\", \"value\": 43}\n",
    "        ]\n",
    "    \n",
    "    # Validate data structure\n",
    "    if not isinstance(data_values, list) or len(data_values) == 0:\n",
    "        data_values = [{\"category\": \"A\", \"value\": 28}]\n",
    "    \n",
    "    # Get field names\n",
    "    try:\n",
    "        first_item = data_values[0]\n",
    "        if not first_item or not isinstance(first_item, dict) or len(first_item.keys()) < 2:\n",
    "            data_values = [{\"category\": \"A\", \"value\": 28}]\n",
    "            fields = [\"category\", \"value\"]\n",
    "        else:\n",
    "            fields = list(first_item.keys())\n",
    "    except (IndexError, AttributeError, TypeError):\n",
    "        fields = [\"category\", \"value\"]\n",
    "    \n",
    "    # Smart field detection - more programmatic and data-driven\n",
    "    def detect_field_types(fields, data_values):\n",
    "        \"\"\"\n",
    "        Programmatically detect field types based on field names and actual data.\n",
    "        Returns: (time_field, category_field, value_fields)\n",
    "        \"\"\"\n",
    "        time_field = None\n",
    "        category_field = None\n",
    "        value_fields = []\n",
    "        \n",
    "        # Keywords for field detection (configurable)\n",
    "        time_keywords = ['year', 'date', 'time', 'month', 'day', 'quarter', 'week']\n",
    "        category_keywords = ['name', 'region', 'category', 'type', 'brand', 'segment', \n",
    "                           'product', 'customer', 'location', 'country', 'state', 'city']\n",
    "        value_keywords = ['sales', 'revenue', 'volume', 'amount', 'value', 'price', \n",
    "                         'qty', 'quantity', 'usd', 'count', 'total', 'sum', 'avg', 'mean']\n",
    "        \n",
    "        for field in fields:\n",
    "            field_lower = field.lower()\n",
    "            \n",
    "            # Get sample value for type checking\n",
    "            sample_value = None\n",
    "            is_numeric = False\n",
    "            is_string = False\n",
    "            try:\n",
    "                sample_value = data_values[0][field]\n",
    "                is_numeric = isinstance(sample_value, (int, float)) and not isinstance(sample_value, bool)\n",
    "                is_string = isinstance(sample_value, str)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # TIME FIELD detection\n",
    "            if any(keyword in field_lower for keyword in time_keywords):\n",
    "                if is_numeric or is_string:\n",
    "                    time_field = field\n",
    "                    continue\n",
    "            elif is_string and sample_value and re.match(r'^\\d{4}', str(sample_value)):\n",
    "                if time_field is None:\n",
    "                    time_field = field\n",
    "                    continue\n",
    "            \n",
    "            # VALUE FIELD detection\n",
    "            if is_numeric:\n",
    "                has_value_keyword = any(keyword in field_lower for keyword in value_keywords)\n",
    "                has_time_keyword = any(keyword in field_lower for keyword in time_keywords)\n",
    "                has_id_keyword = 'id' in field_lower\n",
    "                \n",
    "                if has_value_keyword or (not has_time_keyword and not has_id_keyword):\n",
    "                    value_fields.append(field)\n",
    "                    continue\n",
    "            \n",
    "            # CATEGORY FIELD detection\n",
    "            if is_string:\n",
    "                has_category_keyword = any(keyword in field_lower for keyword in category_keywords)\n",
    "                \n",
    "                if has_category_keyword and category_field is None:\n",
    "                    category_field = field\n",
    "                elif category_field is None:\n",
    "                    category_field = field\n",
    "        \n",
    "        # Fallback logic\n",
    "        if not value_fields:\n",
    "            for field in reversed(fields):\n",
    "                try:\n",
    "                    if isinstance(data_values[0][field], (int, float)):\n",
    "                        value_fields = [field]\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            if not value_fields:\n",
    "                value_fields = [fields[-1]]\n",
    "        \n",
    "        if not category_field and not time_field:\n",
    "            for field in fields:\n",
    "                try:\n",
    "                    if not isinstance(data_values[0][field], (int, float)):\n",
    "                        category_field = field\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            if not category_field:\n",
    "                category_field = fields[0]\n",
    "        \n",
    "        return time_field, category_field, value_fields\n",
    "    \n",
    "    # Helper: Detect if metrics have vastly different scales\n",
    "    def have_different_scales(value_fields, data_values):\n",
    "        \"\"\"\n",
    "        Check if value fields have significantly different scales (>100x difference).\n",
    "        Returns: (bool, scale_info)\n",
    "        \"\"\"\n",
    "        if len(value_fields) < 2:\n",
    "            return False, {}\n",
    "        \n",
    "        # Calculate ranges for each metric\n",
    "        ranges = {}\n",
    "        for field in value_fields:\n",
    "            try:\n",
    "                values = [row[field] for row in data_values if field in row and isinstance(row[field], (int, float))]\n",
    "                if values:\n",
    "                    ranges[field] = {\n",
    "                        'min': min(values),\n",
    "                        'max': max(values),\n",
    "                        'range': max(values) - min(values) if max(values) != min(values) else max(values)\n",
    "                    }\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if len(ranges) < 2:\n",
    "            return False, {}\n",
    "        \n",
    "        # Compare scales\n",
    "        field_list = list(ranges.keys())\n",
    "        max_ratio = 1\n",
    "        for i in range(len(field_list)):\n",
    "            for j in range(i + 1, len(field_list)):\n",
    "                field1, field2 = field_list[i], field_list[j]\n",
    "                if ranges[field2]['range'] > 0:\n",
    "                    ratio = ranges[field1]['range'] / ranges[field2]['range']\n",
    "                    max_ratio = max(max_ratio, ratio, 1/ratio if ratio > 0 else 1)\n",
    "        \n",
    "        # If any ratio > 100, they have different scales\n",
    "        different_scales = max_ratio > 100\n",
    "        \n",
    "        return different_scales, ranges\n",
    "    \n",
    "    time_field, category_field, value_fields = detect_field_types(fields, data_values)\n",
    "    \n",
    "    # Determine primary value field\n",
    "    primary_value_field = value_fields[0] if value_fields else fields[-1]\n",
    "    \n",
    "    description_lower = chart_description.lower()\n",
    "    \n",
    "    # Detect multi-scale scenario\n",
    "    different_scales, scale_info = have_different_scales(value_fields, data_values)\n",
    "    \n",
    "    # Base configuration\n",
    "    base_spec = {\n",
    "        \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "        \"description\": chart_description,\n",
    "        \"data\": {\"values\": data_values},\n",
    "        \"width\": 500,\n",
    "        \"height\": 300\n",
    "    }\n",
    "    \n",
    "    # Chart type logic\n",
    "    if any(word in description_lower for word in [\"line\", \"trend\", \"time series\"]):\n",
    "        # LINE CHART - Time series\n",
    "        x_field = time_field or category_field or fields[0]\n",
    "        y_field = primary_value_field\n",
    "        \n",
    "        # Determine if multi-series (has both time and category)\n",
    "        color_field = None\n",
    "        if time_field and category_field:\n",
    "            x_field = time_field\n",
    "            color_field = category_field\n",
    "        \n",
    "        # Determine x-axis type\n",
    "        x_type = \"ordinal\"\n",
    "        if time_field == x_field:\n",
    "            try:\n",
    "                sample_value = data_values[0][x_field]\n",
    "                if isinstance(sample_value, (int, float)):\n",
    "                    x_type = \"ordinal\"\n",
    "                elif isinstance(sample_value, str):\n",
    "                    if re.match(r'^\\d{4}-\\d{2}-\\d{2}', str(sample_value)):\n",
    "                        x_type = \"temporal\"\n",
    "                    else:\n",
    "                        x_type = \"ordinal\"\n",
    "            except:\n",
    "                x_type = \"ordinal\"\n",
    "        \n",
    "        encoding = {\n",
    "            \"x\": {\n",
    "                \"field\": x_field,\n",
    "                \"type\": x_type,\n",
    "                \"title\": x_field.replace(\"_\", \" \").title()\n",
    "            },\n",
    "            \"y\": {\n",
    "                \"field\": y_field,\n",
    "                \"type\": \"quantitative\",\n",
    "                \"title\": y_field.replace(\"_\", \" \").title()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if color_field:\n",
    "            encoding[\"color\"] = {\n",
    "                \"field\": color_field,\n",
    "                \"type\": \"nominal\",\n",
    "                \"title\": color_field.replace(\"_\", \" \").title()\n",
    "            }\n",
    "        \n",
    "        return json.dumps({\n",
    "            **base_spec,\n",
    "            \"mark\": {\n",
    "                \"type\": \"line\",\n",
    "                \"point\": True,\n",
    "                \"tooltip\": True\n",
    "            },\n",
    "            \"encoding\": encoding,\n",
    "            \"config\": {\n",
    "                \"view\": {\"stroke\": None}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif any(word in description_lower for word in [\"bar\", \"column\", \"histogram\"]):\n",
    "        # BAR CHART\n",
    "        x_field = category_field or time_field or fields[0]\n",
    "        \n",
    "        # Check if this is a year-over-year comparison\n",
    "        is_year_comparison = time_field and (\n",
    "            'compare' in description_lower or\n",
    "            'vs' in description_lower or\n",
    "            'versus' in description_lower or\n",
    "            description_lower.count('year') >= 2\n",
    "        )\n",
    "        \n",
    "        # Check if user wants multi-metric chart\n",
    "        wants_multi_metric = (\n",
    "            len(value_fields) > 1 and \n",
    "            any(keyword in description_lower for keyword in \n",
    "                [\"grouped\", \"two bars\", \"both\", \"multiple\", \"including\", \"compare\", \"two separate\", \"side by side\", \"separate charts\"])\n",
    "        )\n",
    "        \n",
    "        # MULTI-METRIC HANDLING (prioritize explicit user requests)\n",
    "        if wants_multi_metric:\n",
    "            # PRIORITY 1: Check if user explicitly wants side-by-side or separate charts\n",
    "            if any(keyword in description_lower for keyword in [\"side by side\", \"separate charts\", \"two separate\"]):\n",
    "                # Determine orientation\n",
    "                use_horizontal = \"side by side\" in description_lower\n",
    "                \n",
    "                charts = []\n",
    "                for value_field in value_fields:\n",
    "                    chart_spec = {\n",
    "                        \"title\": {\n",
    "                            \"text\": value_field.replace(\"_\", \" \").title(),\n",
    "                            \"fontSize\": 14\n",
    "                        },\n",
    "                        \"width\": 400 if use_horizontal else 500,\n",
    "                        \"height\": 300 if use_horizontal else 200,\n",
    "                        \"mark\": {\"type\": \"bar\", \"tooltip\": True},\n",
    "                        \"encoding\": {\n",
    "                            \"x\": {\n",
    "                                \"field\": x_field,\n",
    "                                \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                                \"axis\": {\"labelAngle\": -45},\n",
    "                                \"title\": x_field.replace(\"_\", \" \").title()\n",
    "                            },\n",
    "                            \"y\": {\n",
    "                                \"field\": value_field,\n",
    "                                \"type\": \"quantitative\",\n",
    "                                \"title\": None\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    # Add year color encoding if year comparison\n",
    "                    if is_year_comparison:\n",
    "                        chart_spec[\"encoding\"][\"color\"] = {\n",
    "                            \"field\": time_field,\n",
    "                            \"type\": \"ordinal\",\n",
    "                            \"title\": time_field.replace(\"_\", \" \").title(),\n",
    "                            \"scale\": {\"range\": [\"#4c78a8\", \"#f58518\"]}  # blue and orange\n",
    "                        }\n",
    "                        chart_spec[\"encoding\"][\"xOffset\"] = {\"field\": time_field}\n",
    "                    \n",
    "                    charts.append(chart_spec)\n",
    "                \n",
    "                concat_key = \"hconcat\" if use_horizontal else \"vconcat\"\n",
    "                return json.dumps({\n",
    "                    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "                    \"description\": chart_description,\n",
    "                    \"data\": {\"values\": data_values},\n",
    "                    concat_key: charts,\n",
    "                    \"resolve\": {\n",
    "                        \"scale\": {\"y\": \"independent\"}\n",
    "                    },\n",
    "                    \"config\": {\n",
    "                        \"view\": {\"stroke\": None}\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # PRIORITY 2: DUAL-AXIS CHART (for 2 metrics with different scales, no explicit layout request)\n",
    "            elif different_scales and len(value_fields) == 2:\n",
    "                return json.dumps({\n",
    "                    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "                    \"description\": chart_description,\n",
    "                    \"data\": {\"values\": data_values},\n",
    "                    \"width\": 500,\n",
    "                    \"height\": 300,\n",
    "                    \"layer\": [\n",
    "                        {\n",
    "                            \"mark\": {\"type\": \"bar\", \"opacity\": 0.7, \"color\": \"#4c78a8\", \"tooltip\": True},\n",
    "                            \"encoding\": {\n",
    "                                \"x\": {\n",
    "                                    \"field\": x_field,\n",
    "                                    \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                                    \"axis\": {\"labelAngle\": -45},\n",
    "                                    \"title\": x_field.replace(\"_\", \" \").title()\n",
    "                                },\n",
    "                                \"y\": {\n",
    "                                    \"field\": value_fields[0],\n",
    "                                    \"type\": \"quantitative\",\n",
    "                                    \"title\": value_fields[0].replace(\"_\", \" \").title(),\n",
    "                                    \"axis\": {\"titleColor\": \"#4c78a8\"}\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"mark\": {\n",
    "                                \"type\": \"line\",\n",
    "                                \"color\": \"#e45756\",\n",
    "                                \"point\": {\"filled\": True, \"size\": 80},\n",
    "                                \"strokeWidth\": 3,\n",
    "                                \"tooltip\": True\n",
    "                            },\n",
    "                            \"encoding\": {\n",
    "                                \"x\": {\n",
    "                                    \"field\": x_field,\n",
    "                                    \"type\": \"nominal\" if category_field == x_field else \"ordinal\"\n",
    "                                },\n",
    "                                \"y\": {\n",
    "                                    \"field\": value_fields[1],\n",
    "                                    \"type\": \"quantitative\",\n",
    "                                    \"title\": value_fields[1].replace(\"_\", \" \").title(),\n",
    "                                    \"axis\": {\"titleColor\": \"#e45756\", \"orient\": \"right\"}\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"resolve\": {\n",
    "                        \"scale\": {\"y\": \"independent\"}\n",
    "                    },\n",
    "                    \"config\": {\n",
    "                        \"view\": {\"stroke\": None}\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # PRIORITY 3: VERTICAL SUBPLOTS (for 3+ metrics or different scales)\n",
    "            elif different_scales or len(value_fields) > 2:\n",
    "                charts = []\n",
    "                for value_field in value_fields:\n",
    "                    chart_spec = {\n",
    "                        \"title\": {\n",
    "                            \"text\": value_field.replace(\"_\", \" \").title(),\n",
    "                            \"fontSize\": 14\n",
    "                        },\n",
    "                        \"width\": 500,\n",
    "                        \"height\": 200,\n",
    "                        \"mark\": {\"type\": \"bar\", \"tooltip\": True},\n",
    "                        \"encoding\": {\n",
    "                            \"x\": {\n",
    "                                \"field\": x_field,\n",
    "                                \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                                \"axis\": {\"labelAngle\": -45},\n",
    "                                \"title\": x_field.replace(\"_\", \" \").title()\n",
    "                            },\n",
    "                            \"y\": {\n",
    "                                \"field\": value_field,\n",
    "                                \"type\": \"quantitative\",\n",
    "                                \"title\": None\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    # Add year color encoding if year comparison\n",
    "                    if is_year_comparison:\n",
    "                        chart_spec[\"encoding\"][\"color\"] = {\n",
    "                            \"field\": time_field,\n",
    "                            \"type\": \"ordinal\",\n",
    "                            \"title\": time_field.replace(\"_\", \" \").title()\n",
    "                        }\n",
    "                        chart_spec[\"encoding\"][\"xOffset\"] = {\"field\": time_field}\n",
    "                    \n",
    "                    charts.append(chart_spec)\n",
    "                \n",
    "                return json.dumps({\n",
    "                    \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "                    \"description\": chart_description,\n",
    "                    \"data\": {\"values\": data_values},\n",
    "                    \"vconcat\": charts,\n",
    "                    \"resolve\": {\n",
    "                        \"scale\": {\"y\": \"independent\"}\n",
    "                    },\n",
    "                    \"config\": {\n",
    "                        \"view\": {\"stroke\": None}\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # PRIORITY 4: STANDARD GROUPED BARS (same scale)\n",
    "            else:\n",
    "                transformed_data = []\n",
    "                for row in data_values:\n",
    "                    for value_field in value_fields:\n",
    "                        transformed_data.append({\n",
    "                            x_field: row[x_field],\n",
    "                            \"metric\": value_field.replace(\"_\", \" \").title(),\n",
    "                            \"value\": row[value_field]\n",
    "                        })\n",
    "                \n",
    "                return json.dumps({\n",
    "                    **base_spec,\n",
    "                    \"data\": {\"values\": transformed_data},\n",
    "                    \"mark\": {\n",
    "                        \"type\": \"bar\",\n",
    "                        \"tooltip\": True\n",
    "                    },\n",
    "                    \"encoding\": {\n",
    "                        \"x\": {\n",
    "                            \"field\": x_field,\n",
    "                            \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                            \"axis\": {\"labelAngle\": -45}\n",
    "                        },\n",
    "                        \"y\": {\n",
    "                            \"field\": \"value\",\n",
    "                            \"type\": \"quantitative\",\n",
    "                            \"title\": \"Value\"\n",
    "                        },\n",
    "                        \"color\": {\n",
    "                            \"field\": \"metric\",\n",
    "                            \"type\": \"nominal\",\n",
    "                            \"title\": \"Metric\"\n",
    "                        },\n",
    "                        \"xOffset\": {\n",
    "                            \"field\": \"metric\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"config\": {\n",
    "                        \"view\": {\"stroke\": None}\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        # YEAR COMPARISON (single metric)\n",
    "        elif is_year_comparison:\n",
    "            primary_metric = value_fields[0] if value_fields else fields[-1]\n",
    "            \n",
    "            return json.dumps({\n",
    "                **base_spec,\n",
    "                \"mark\": {\n",
    "                    \"type\": \"bar\",\n",
    "                    \"tooltip\": True\n",
    "                },\n",
    "                \"encoding\": {\n",
    "                    \"x\": {\n",
    "                        \"field\": x_field,\n",
    "                        \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                        \"axis\": {\"labelAngle\": -45}\n",
    "                    },\n",
    "                    \"y\": {\n",
    "                        \"field\": primary_metric,\n",
    "                        \"type\": \"quantitative\",\n",
    "                        \"title\": primary_metric.replace(\"_\", \" \").title()\n",
    "                    },\n",
    "                    \"color\": {\n",
    "                        \"field\": time_field,\n",
    "                        \"type\": \"ordinal\",\n",
    "                        \"title\": time_field.replace(\"_\", \" \").title()\n",
    "                    },\n",
    "                    \"xOffset\": {\n",
    "                        \"field\": time_field\n",
    "                    }\n",
    "                },\n",
    "                \"config\": {\n",
    "                    \"view\": {\"stroke\": None}\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # SINGLE METRIC BAR CHART\n",
    "        y_field = primary_value_field\n",
    "        \n",
    "        return json.dumps({\n",
    "            **base_spec,\n",
    "            \"mark\": {\n",
    "                \"type\": \"bar\",\n",
    "                \"tooltip\": True\n",
    "            },\n",
    "            \"encoding\": {\n",
    "                \"x\": {\n",
    "                    \"field\": x_field,\n",
    "                    \"type\": \"nominal\" if category_field == x_field else \"ordinal\",\n",
    "                    \"axis\": {\"labelAngle\": -45}\n",
    "                },\n",
    "                \"y\": {\n",
    "                    \"field\": y_field,\n",
    "                    \"type\": \"quantitative\"\n",
    "                }\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"view\": {\"stroke\": None}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif any(word in description_lower for word in [\"scatter\", \"point\"]):\n",
    "        # SCATTER PLOT\n",
    "        x_field = fields[0] if len(fields) >= 2 else \"x\"\n",
    "        y_field = fields[1] if len(fields) >= 2 else \"y\"\n",
    "        \n",
    "        return json.dumps({\n",
    "            **base_spec,\n",
    "            \"mark\": {\n",
    "                \"type\": \"point\",\n",
    "                \"tooltip\": True\n",
    "            },\n",
    "            \"encoding\": {\n",
    "                \"x\": {\"field\": x_field, \"type\": \"quantitative\"},\n",
    "                \"y\": {\"field\": y_field, \"type\": \"quantitative\"}\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"view\": {\"stroke\": None}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    elif any(word in description_lower for word in [\"pie\", \"donut\"]):\n",
    "        # PIE CHART\n",
    "        category = category_field or fields[0]\n",
    "        value = primary_value_field\n",
    "        \n",
    "        return json.dumps({\n",
    "            **base_spec,\n",
    "            \"mark\": {\"type\": \"arc\", \"tooltip\": True},\n",
    "            \"encoding\": {\n",
    "                \"theta\": {\"field\": value, \"type\": \"quantitative\"},\n",
    "                \"color\": {\"field\": category, \"type\": \"nominal\"}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    else:\n",
    "        # DEFAULT: BAR CHART\n",
    "        x_field = category_field or fields[0]\n",
    "        y_field = primary_value_field\n",
    "        \n",
    "        return json.dumps({\n",
    "            **base_spec,\n",
    "            \"mark\": {\n",
    "                \"type\": \"bar\",\n",
    "                \"tooltip\": True\n",
    "            },\n",
    "            \"encoding\": {\n",
    "                \"x\": {\n",
    "                    \"field\": x_field,\n",
    "                    \"type\": \"nominal\",\n",
    "                    \"axis\": {\"labelAngle\": -45}\n",
    "                },\n",
    "                \"y\": {\n",
    "                    \"field\": y_field,\n",
    "                    \"type\": \"quantitative\"\n",
    "                }\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"view\": {\"stroke\": None}\n",
    "            }\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de06db8-e2d2-4011-996e-54e6b2395bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Register as UC Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6327b035-7f26-42b4-a187-e402d97a06ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-31673932-c449-4265-adb5-1fefb9392461/lib/python3.10/site-packages/databricks/connect/session.py:451: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating UC Function: main_david_thomas.default.generate_vega_lite_spec\n✅ UC Function created successfully!\nFunction name: main_david_thomas.default.generate_vega_lite_spec\n\n\uD83D\uDCCD MCP URL: https://adb-361426925668745.5.azuredatabricks.net/api/2.0/mcp/functions/main_david_thomas/default\n"
     ]
    }
   ],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Initialize clients\n",
    "client = DatabricksFunctionClient()\n",
    "w = WorkspaceClient()  # For getting workspace URL\n",
    "\n",
    "full_function_name = f\"{CATALOG}.{SCHEMA}.generate_vega_lite_spec\"\n",
    "\n",
    "print(f\"Creating UC Function: {full_function_name}\")\n",
    "\n",
    "# Create the function using the high-level API\n",
    "function_info = client.create_python_function(\n",
    "    func=generate_vega_lite_spec,\n",
    "    catalog=CATALOG,\n",
    "    schema=SCHEMA,\n",
    "    replace=True  # Overwrites existing function if it exists\n",
    ")\n",
    "\n",
    "print(f\"✅ UC Function created successfully!\")\n",
    "print(f\"Function name: {function_info.full_name}\")\n",
    "print(f\"\\n\uD83D\uDCCD MCP URL: {w.config.host}/api/2.0/mcp/functions/{CATALOG}/{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80a141e6-cf8a-4da6-880e-f78b95bb0b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Test the UC Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94d1fdc8-e750-485b-b29a-02660494f50e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Bar chart with default data\n------------------------------------------------------------\n✅ Result:\n{\n  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n  \"description\": \"bar chart of sales\",\n  \"data\": {\n    \"values\": [\n      {\n        \"category\": \"A\",\n        \"value\": 28\n      },\n      {\n        \"category\": \"B\",\n        \"value\": 55\n      },\n      {\n        \"category\": \"C\",\n        \"value\": 43\n      }\n    ]\n  },\n  \"width\": 500,\n  \"height\": 300,\n  \"mark\": {\n    \"type\": \"bar\",\n    \"tooltip\": true\n  },\n  \"encoding\": {\n    \"x\": {\n      \"field\": \"category\",\n      \"type\": \"nominal\",\n      \"axis\": {\n        \"labelAngle\": -45\n      }\n    },\n    \"y\": {\n      \"field\": \"value\",\n      \"type\": \"quantitative\"\n    }\n  },\n  \"config\": {\n    \"view\": {\n      \"stroke\": null\n    }\n  }\n}\n\nTest 2: Line chart with custom data\n------------------------------------------------------------\n✅ Result:\n{\n  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n  \"description\": \"line chart showing revenue trend\",\n  \"data\": {\n    \"values\": [\n      {\n        \"month\": \"Jan\",\n        \"revenue\": 10000\n      },\n      {\n        \"month\": \"Feb\",\n        \"revenue\": 15000\n      },\n      {\n        \"month\": \"Mar\",\n        \"revenue\": 13000\n      },\n      {\n        \"month\": \"Apr\",\n        \"revenue\": 18000\n      }\n    ]\n  },\n  \"width\": 500,\n  \"height\": 300,\n  \"mark\": {\n    \"type\": \"line\",\n    \"point\": true,\n    \"tooltip\": true\n  },\n  \"encoding\": {\n    \"x\": {\n      \"field\": \"month\",\n      \"type\": \"ordinal\",\n      \"title\": \"Month\"\n    },\n    \"y\": {\n      \"field\": \"revenue\",\n      \"type\": \"quantitative\",\n      \"title\": \"Revenue\"\n    }\n  },\n  \"config\": {\n    \"view\": {\n      \"stroke\": null\n    }\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Reuse the DatabricksFunctionClient for testing\n",
    "# client = DatabricksFunctionClient()  # Already initialized above\n",
    "\n",
    "print(\"Test 1: Bar chart with default data\")\n",
    "print(\"-\" * 60)\n",
    "result_1 = client.execute_function(\n",
    "    full_function_name,\n",
    "    {\"chart_description\": \"bar chart of sales\", \"data_sample\": \"\"}  # Empty string for default data\n",
    ")\n",
    "print(f\"✅ Result:\\n{json.dumps(json.loads(result_1.value), indent=2)}\")\n",
    "print()\n",
    "\n",
    "print(\"Test 2: Line chart with custom data\")\n",
    "print(\"-\" * 60)\n",
    "sample_data = json.dumps([\n",
    "    {\"month\": \"Jan\", \"revenue\": 10000},\n",
    "    {\"month\": \"Feb\", \"revenue\": 15000},\n",
    "    {\"month\": \"Mar\", \"revenue\": 13000},\n",
    "    {\"month\": \"Apr\", \"revenue\": 18000}\n",
    "])\n",
    "result_2 = client.execute_function(\n",
    "    full_function_name,\n",
    "    {\"chart_description\": \"line chart showing revenue trend\", \"data_sample\": sample_data}\n",
    ")\n",
    "print(f\"✅ Result:\\n{json.dumps(json.loads(result_2.value), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c469cd66-fd11-47e6-933d-b6b46f25120d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Visualize the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a78435-b7ca-4808-aec7-8e37282a5299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "  <script src=\"https://cdn.jsdelivr.net/npm/vega@5\"></script>\n",
       "  <script src=\"https://cdn.jsdelivr.net/npm/vega-lite@5\"></script>\n",
       "  <script src=\"https://cdn.jsdelivr.net/npm/vega-embed@6\"></script>\n",
       "  <style>\n",
       "    body { background: #f5f5f5; padding: 20px; }\n",
       "    #vis { background: white; padding: 20px; border-radius: 8px; }\n",
       "  </style>\n",
       "</head>\n",
       "<body>\n",
       "  <h2>Generated Vega-Lite Visualization</h2>\n",
       "  <div id=\"vis\"></div>\n",
       "  <script>\n",
       "    vegaEmbed('#vis', {\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"description\": \"line chart showing revenue trend\", \"data\": {\"values\": [{\"month\": \"Jan\", \"revenue\": 10000}, {\"month\": \"Feb\", \"revenue\": 15000}, {\"month\": \"Mar\", \"revenue\": 13000}, {\"month\": \"Apr\", \"revenue\": 18000}]}, \"width\": 500, \"height\": 300, \"mark\": {\"type\": \"line\", \"point\": true, \"tooltip\": true}, \"encoding\": {\"x\": {\"field\": \"month\", \"type\": \"ordinal\", \"title\": \"Month\"}, \"y\": {\"field\": \"revenue\", \"type\": \"quantitative\", \"title\": \"Revenue\"}}, \"config\": {\"view\": {\"stroke\": null}}}, {theme: 'latimes'});\n",
       "  </script>\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the line chart\n",
    "vega_spec = json.loads(result_2.value)\n",
    "\n",
    "# displayHTML only works in Databricks notebooks, not local execution\n",
    "try:\n",
    "    displayHTML(f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega@5\"></script>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega-lite@5\"></script>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/vega-embed@6\"></script>\n",
    "  <style>\n",
    "    body {{ background: #f5f5f5; padding: 20px; }}\n",
    "    #vis {{ background: white; padding: 20px; border-radius: 8px; }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h2>Generated Vega-Lite Visualization</h2>\n",
    "  <div id=\"vis\"></div>\n",
    "  <script>\n",
    "    vegaEmbed('#vis', {json.dumps(vega_spec)}, {{theme: 'latimes'}});\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\")\n",
    "except NameError:\n",
    "    print(\"Note: displayHTML only works in Databricks notebooks, not local execution\")\n",
    "    print(f\"Vega spec generated:\\n{json.dumps(vega_spec, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9736bf9d-3e38-40a6-885d-57dfc01a67eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Test in Serverless Mode (Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e196978-d75e-4dd9-a4ae-a370f5447d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing scatter plot...\n------------------------------------------------------------\n✅ Execution successful!\nResult: {\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"description\": \"scatter plot\", \"data\"...\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing scatter plot...\")\n",
    "print(\"-\" * 60)\n",
    "result_prod = client.execute_function(\n",
    "    full_function_name,\n",
    "    {\n",
    "        \"chart_description\": \"scatter plot\",\n",
    "        \"data_sample\": json.dumps([\n",
    "            {\"x\": 1, \"y\": 2},\n",
    "            {\"x\": 2, \"y\": 4},\n",
    "            {\"x\": 3, \"y\": 6},\n",
    "            {\"x\": 4, \"y\": 8}\n",
    "        ])\n",
    "    }\n",
    ")\n",
    "print(f\"✅ Execution successful!\")\n",
    "print(f\"Result: {result_prod.value[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "814ad669-7321-4d6d-ad40-ee8dd4f8d5f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ✅ Success! Your UC Function is Ready\n",
    "\n",
    "### What You Created:\n",
    "- ✅ UC Function: `{CATALOG}.{SCHEMA}.generate_vega_lite_spec`\n",
    "- ✅ Tested in local mode (fast)\n",
    "- ✅ Tested in serverless mode (production)\n",
    "- ✅ Visualized the output\n",
    "\n",
    "### MCP Access:\n",
    "```\n",
    "{workspace_url}/api/2.0/mcp/functions/{CATALOG}/{SCHEMA}\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "1. Configure your agent to use this MCP endpoint\n",
    "2. The agent will auto-discover `generate_vega_lite_spec`\n",
    "3. When users ask for visualizations, the agent calls your function\n",
    "4. Your app renders the returned Vega-Lite spec\n",
    "\n",
    "### Grant Permissions:\n",
    "```sql\n",
    "GRANT EXECUTE ON FUNCTION {full_function_name} TO `<principal>`;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_vegalite_uc_function_simple_template",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}